{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f679f3a0",
   "metadata": {},
   "source": [
    "# 1. Amazon data based check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24193e",
   "metadata": {},
   "source": [
    "## 1) Measuring Market Entry Progress by Item (#10, 30, 50, 100 interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7949120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 5)\n",
      "┌─────┬────────┬────────────┬─────────────┬─────────────┐\n",
      "│ n   ┆ count  ┆ reach_rate ┆ mean_days   ┆ median_days │\n",
      "│ --- ┆ ---    ┆ ---        ┆ ---         ┆ ---         │\n",
      "│ i64 ┆ i64    ┆ f64        ┆ f64         ┆ f64         │\n",
      "╞═════╪════════╪════════════╪═════════════╪═════════════╡\n",
      "│ 10  ┆ 440995 ┆ 0.577494   ┆ 531.173514  ┆ 344.449132  │\n",
      "│ 30  ┆ 158671 ┆ 0.207784   ┆ 832.735617  ┆ 600.448206  │\n",
      "│ 50  ┆ 95592  ┆ 0.12518    ┆ 987.320446  ┆ 742.468744  │\n",
      "│ 100 ┆ 46410  ┆ 0.060775   ┆ 1215.037832 ┆ 939.190162  │\n",
      "└─────┴────────┴────────────┴─────────────┴─────────────┘\n",
      "saved to /home/heek/aigs/NTS/reachtime_amazon/home_itm_summary.csv\n",
      "elapsed: 8.25s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import polars as pl\n",
    "\n",
    "BASE = Path(\"/home/heek/edda_backbone/preprocess_raw/amazon/23/user_reviews/5_core\")\n",
    "SRC = BASE / \"Home_and_Kitchen.json\"\n",
    "\n",
    "OUT_DIR = Path(\"/home/heek/aigs/NTS/reachtime_amazon\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PATH = OUT_DIR / \"home_itm_summary.csv\"\n",
    "\n",
    "N_LIST = [10, 30, 50, 100]\n",
    "\n",
    "\n",
    "def now() -> float:\n",
    "    return time.perf_counter()\n",
    "\n",
    "\n",
    "def home_summary() -> None:\n",
    "    if not SRC.exists():\n",
    "        print(f\"missing file: {SRC}\")\n",
    "        return\n",
    "\n",
    "    t0 = now()\n",
    "\n",
    "    scan = (\n",
    "        pl.scan_ndjson(SRC)\n",
    "        .select(\n",
    "            pl.col(\"user_id\").cast(pl.Utf8),\n",
    "            pl.col(\"parent_asin\").cast(pl.Utf8).alias(\"item_id\"),\n",
    "            pl.col(\"timestamp\").cast(pl.Float64).alias(\"ts_raw\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        scan.with_columns(\n",
    "            pl.when(pl.col(\"ts_raw\") > 1e11)\n",
    "            .then(pl.col(\"ts_raw\") / 1000.0)\n",
    "            .otherwise(pl.col(\"ts_raw\"))\n",
    "            .alias(\"ts_s\")\n",
    "        )\n",
    "        .select(\n",
    "            pl.col(\"user_id\"),\n",
    "            pl.col(\"item_id\"),\n",
    "            pl.col(\"ts_s\").round(0).cast(pl.Int64).alias(\"ts\"),\n",
    "        )\n",
    "        .unique(subset=[\"user_id\", \"item_id\", \"ts\"])\n",
    "        .collect(engine=\"streaming\")\n",
    "    )\n",
    "\n",
    "    if df.is_empty():\n",
    "        print(\"empty dataframe\")\n",
    "        return\n",
    "\n",
    "    df_sorted = df.sort([\"item_id\", \"ts\"])\n",
    "    df_cc = df_sorted.with_columns(\n",
    "        pl.int_range(0, pl.len()).over(\"item_id\").alias(\"cc\")\n",
    "    )\n",
    "\n",
    "    t0_tbl = df_sorted.group_by(\"item_id\").agg(pl.col(\"ts\").first().alias(\"t0\"))\n",
    "    t_last_tbl = df_sorted.group_by(\"item_id\").agg(pl.col(\"ts\").last().alias(\"t_last\"))\n",
    "    total_tbl = df_sorted.group_by(\"item_id\").len().rename({\"len\": \"total_cnt\"})\n",
    "\n",
    "    items = (\n",
    "        t0_tbl.join(t_last_tbl, on=\"item_id\")\n",
    "        .join(total_tbl, on=\"item_id\")\n",
    "    )\n",
    "\n",
    "    for n in N_LIST:\n",
    "        idx = n - 1\n",
    "        tn = (\n",
    "            df_cc.filter(pl.col(\"cc\") == idx)\n",
    "            .select([\"item_id\", pl.col(\"ts\").alias(f\"t{n}\")])\n",
    "        )\n",
    "        items = items.join(tn, on=\"item_id\", how=\"left\")\n",
    "\n",
    "    total_items = items.height\n",
    "\n",
    "    rows = []\n",
    "    for n in N_LIST:\n",
    "        items = items.with_columns(\n",
    "            ((pl.col(f\"t{n}\") - pl.col(\"t0\")) / 86400.0)\n",
    "            .cast(pl.Float64)\n",
    "            .alias(f\"days_{n}\")\n",
    "        )\n",
    "        reached = items.filter(pl.col(f\"t{n}\").is_not_null())\n",
    "\n",
    "        if reached.height == 0 or total_items == 0:\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"n\": n,\n",
    "                    \"count\": 0,\n",
    "                    \"reach_rate\": 0.0,\n",
    "                    \"mean_days\": None,\n",
    "                    \"median_days\": None,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        cnt, mean_days, median_days = reached.select(\n",
    "            pl.len().alias(\"count\"),\n",
    "            pl.col(f\"days_{n}\").mean().alias(\"mean_days\"),\n",
    "            pl.col(f\"days_{n}\").median().alias(\"median_days\"),\n",
    "        ).row(0)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"n\": n,\n",
    "                \"count\": cnt,\n",
    "                \"reach_rate\": float(cnt) / float(total_items),\n",
    "                \"mean_days\": mean_days,\n",
    "                \"median_days\": median_days,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary = pl.DataFrame(rows).sort(\"n\")\n",
    "    summary.write_csv(OUT_PATH)\n",
    "\n",
    "    t1 = now()\n",
    "    print(summary)\n",
    "    print(f\"saved to {OUT_PATH}\")\n",
    "    print(f\"elapsed: {t1 - t0:,.2f}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    home_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7c609",
   "metadata": {},
   "source": [
    "## 2) more than 100 interactions item based estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467dd342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items with >= 100 interactions: 46410\n",
      "shape: (4, 3)\n",
      "┌─────┬─────────────┬─────────────┐\n",
      "│ n   ┆ mean_days   ┆ median_days │\n",
      "│ --- ┆ ---         ┆ ---         │\n",
      "│ i64 ┆ f64         ┆ f64         │\n",
      "╞═════╪═════════════╪═════════════╡\n",
      "│ 10  ┆ 315.394416  ┆ 157.355168  │\n",
      "│ 30  ┆ 579.000792  ┆ 364.711539  │\n",
      "│ 50  ┆ 762.539871  ┆ 521.012101  │\n",
      "│ 100 ┆ 1215.037832 ┆ 939.190162  │\n",
      "└─────┴─────────────┴─────────────┘\n",
      "saved to /home/heek/aigs/NTS/reachtime_amazon/home_itm_ge100_summary.csv\n",
      "elapsed: 7.78s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import polars as pl\n",
    "\n",
    "BASE = Path(\"/home/heek/edda_backbone/preprocess_raw/amazon/23/user_reviews/5_core\")\n",
    "SRC = BASE / \"Home_and_Kitchen.json\"\n",
    "\n",
    "OUT_DIR = Path(\"/home/heek/aigs/NTS/reachtime_amazon\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PATH = OUT_DIR / \"home_itm_ge100_summary.csv\"\n",
    "\n",
    "N_LIST = [10, 30, 50, 100]\n",
    "\n",
    "\n",
    "def now() -> float:\n",
    "    return time.perf_counter()\n",
    "\n",
    "\n",
    "def home_summary_ge100() -> None:\n",
    "    if not SRC.exists():\n",
    "        print(f\"missing file: {SRC}\")\n",
    "        return\n",
    "\n",
    "    t0 = now()\n",
    "\n",
    "    scan = (\n",
    "        pl.scan_ndjson(SRC)\n",
    "        .select(\n",
    "            pl.col(\"user_id\").cast(pl.Utf8),\n",
    "            pl.col(\"parent_asin\").cast(pl.Utf8).alias(\"item_id\"),\n",
    "            pl.col(\"timestamp\").cast(pl.Float64).alias(\"ts_raw\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        scan.with_columns(\n",
    "            pl.when(pl.col(\"ts_raw\") > 1e11)\n",
    "            .then(pl.col(\"ts_raw\") / 1000.0)\n",
    "            .otherwise(pl.col(\"ts_raw\"))\n",
    "            .alias(\"ts_s\")\n",
    "        )\n",
    "        .select(\n",
    "            pl.col(\"user_id\"),\n",
    "            pl.col(\"item_id\"),\n",
    "            pl.col(\"ts_s\").round(0).cast(pl.Int64).alias(\"ts\"),\n",
    "        )\n",
    "        .unique(subset=[\"user_id\", \"item_id\", \"ts\"])\n",
    "        .collect(engine=\"streaming\")\n",
    "    )\n",
    "\n",
    "    if df.is_empty():\n",
    "        print(\"empty dataframe\")\n",
    "        return\n",
    "\n",
    "    df_sorted = df.sort([\"item_id\", \"ts\"])\n",
    "    df_cc = df_sorted.with_columns(\n",
    "        pl.int_range(0, pl.len()).over(\"item_id\").alias(\"cc\")\n",
    "    )\n",
    "\n",
    "    t0_tbl = df_sorted.group_by(\"item_id\").agg(pl.col(\"ts\").first().alias(\"t0\"))\n",
    "    t_last_tbl = df_sorted.group_by(\"item_id\").agg(pl.col(\"ts\").last().alias(\"t_last\"))\n",
    "    total_tbl = df_sorted.group_by(\"item_id\").len().rename({\"len\": \"total_cnt\"})\n",
    "\n",
    "    items = (\n",
    "        t0_tbl.join(t_last_tbl, on=\"item_id\")\n",
    "        .join(total_tbl, on=\"item_id\")\n",
    "    )\n",
    "\n",
    "    for n in N_LIST:\n",
    "        idx = n - 1\n",
    "        tn = (\n",
    "            df_cc.filter(pl.col(\"cc\") == idx)\n",
    "            .select([\"item_id\", pl.col(\"ts\").alias(f\"t{n}\")])\n",
    "        )\n",
    "        items = items.join(tn, on=\"item_id\", how=\"left\")\n",
    "\n",
    "    core = items.filter(pl.col(\"total_cnt\") >= 100)\n",
    "    total_core = core.height\n",
    "\n",
    "    if total_core == 0:\n",
    "        print(\"no items with >= 100 interactions\")\n",
    "        return\n",
    "\n",
    "    print(f\"items with >= 100 interactions: {total_core}\")\n",
    "\n",
    "    rows = []\n",
    "    for n in N_LIST:\n",
    "        tmp = core.with_columns(\n",
    "            ((pl.col(f\"t{n}\") - pl.col(\"t0\")) / 86400.0)\n",
    "            .cast(pl.Float64)\n",
    "            .alias(f\"days_{n}\")\n",
    "        )\n",
    "        reached = tmp.filter(pl.col(f\"t{n}\").is_not_null())\n",
    "\n",
    "        if reached.is_empty():\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"n\": n,\n",
    "                    \"mean_days\": None,\n",
    "                    \"median_days\": None,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        mean_days, median_days = reached.select(\n",
    "            pl.col(f\"days_{n}\").mean().alias(\"mean_days\"),\n",
    "            pl.col(f\"days_{n}\").median().alias(\"median_days\"),\n",
    "        ).row(0)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"n\": n,\n",
    "                \"mean_days\": mean_days,\n",
    "                \"median_days\": median_days,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary = pl.DataFrame(rows).sort(\"n\")\n",
    "    summary.write_csv(OUT_PATH)\n",
    "\n",
    "    t1 = now()\n",
    "    print(summary)\n",
    "    print(f\"saved to {OUT_PATH}\")\n",
    "    print(f\"elapsed: {t1 - t0:,.2f}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    home_summary_ge100()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cee29",
   "metadata": {},
   "source": [
    "# 2. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e173a59b",
   "metadata": {},
   "source": [
    "## 1) Home and Kitchen domain Pre-estimation about ITEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35232d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using JSON: /home/heek/edda_backbone/preprocess_raw/amazon/23/user_reviews/5_core/Home_and_Kitchen.json\n",
      "The Number of users who interacted items at least once in each 3 groups:  689755\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "BASE = Path(\"/home/heek/edda_backbone/preprocess_raw/amazon/23/user_reviews/5_core\")\n",
    "FILE = BASE / \"Home_and_Kitchen.json\"\n",
    "\n",
    "if not FILE.exists():\n",
    "    raise FileNotFoundError(FILE)\n",
    "\n",
    "print(\"Using JSON:\", FILE)\n",
    "\n",
    "item_count = Counter()\n",
    "with FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        d = json.loads(line)\n",
    "        item_id = d.get(\"parent_asin\") or d.get(\"asin\")\n",
    "        if item_id:\n",
    "            item_count[item_id] += 1\n",
    "\n",
    "counts_sorted = sorted(item_count.values())\n",
    "n_items = len(counts_sorted)\n",
    "\n",
    "idx1 = n_items // 3\n",
    "idx2 = (2 * n_items) // 3\n",
    "\n",
    "thr1 = counts_sorted[idx1]\n",
    "thr2 = counts_sorted[idx2]\n",
    "\n",
    "def get_group(cnt):\n",
    "    if cnt <= thr1:\n",
    "        return 0\n",
    "    elif cnt <= thr2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "user_sets = [set(), set(), set()]\n",
    "with FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        d = json.loads(line)\n",
    "        user = d.get(\"user_id\")\n",
    "        item_id = d.get(\"parent_asin\") or d.get(\"asin\")\n",
    "        if not user or not item_id:\n",
    "            continue\n",
    "\n",
    "        cnt = item_count[item_id]\n",
    "        group = get_group(cnt)\n",
    "        user_sets[group].add(user)\n",
    "\n",
    "users_all_three = set.intersection(*user_sets)\n",
    "\n",
    "print(\"The Number of users who interacted items at least once in each 3 groups: \", len(users_all_three))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4f3411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using JSON: /home/heek/edda_backbone/preprocess_raw/amazon/23/user_reviews/5_core/Home_and_Kitchen.json\n",
      "#items=763636, thr1=8, thr2=18\n",
      "Number of users interacting across all three groups: 689755\n",
      "Selected top users: 5000\n",
      "\n",
      "==== Top 5,000 balanced users: Group interaction statistics ====\n",
      "group  min  Q1   mean  Q3  max\n",
      "    L    2 2.0 2.3786 3.0   19\n",
      "    M    2 2.0 2.4306 3.0   19\n",
      "    H    2 2.0 2.6722 3.0   18\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "BASE = Path(\"/home/heek/edda_backbone/preprocess_raw/amazon/23/user_reviews/5_core\")\n",
    "FILE = BASE / \"Home_and_Kitchen.json\"\n",
    "\n",
    "if not FILE.exists():\n",
    "    raise FileNotFoundError(FILE)\n",
    "\n",
    "print(\"Using JSON:\", FILE)\n",
    "\n",
    "\n",
    "item_count = Counter()\n",
    "with FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        d = json.loads(line)\n",
    "        item_id = d.get(\"parent_asin\") or d.get(\"asin\")\n",
    "        if item_id:\n",
    "            item_count[item_id] += 1\n",
    "\n",
    "if not item_count:\n",
    "    raise RuntimeError(\"item_count is empty\")\n",
    "\n",
    "counts_sorted = sorted(item_count.values())\n",
    "n_items = len(counts_sorted)\n",
    "\n",
    "idx1 = n_items // 3\n",
    "idx2 = (2 * n_items) // 3\n",
    "\n",
    "thr1 = counts_sorted[idx1]\n",
    "thr2 = counts_sorted[idx2]\n",
    "\n",
    "print(f\"#items={n_items}, thr1={thr1}, thr2={thr2}\")\n",
    "\n",
    "\n",
    "def get_group_idx(cnt: int) -> int:\n",
    "    if cnt <= thr1:\n",
    "        return 0   # L\n",
    "    elif cnt <= thr2:\n",
    "        return 1   # M\n",
    "    else:\n",
    "        return 2   # H\n",
    "\n",
    "\n",
    "user_group_cnts = defaultdict(lambda: [0, 0, 0])\n",
    "\n",
    "with FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        d = json.loads(line)\n",
    "        user_id = d.get(\"user_id\")\n",
    "        item_id = d.get(\"parent_asin\") or d.get(\"asin\")\n",
    "        if not user_id or not item_id:\n",
    "            continue\n",
    "\n",
    "        cnt = item_count.get(item_id)\n",
    "        if cnt is None:\n",
    "            continue\n",
    "        g_idx = get_group_idx(cnt)\n",
    "        user_group_cnts[user_id][g_idx] += 1\n",
    "\n",
    "filtered_users = {\n",
    "    u: cnts for u, cnts in user_group_cnts.items()\n",
    "    if all(c > 0 for c in cnts)\n",
    "}\n",
    "\n",
    "print(\"Number of users interacting across all three groups:\", len(filtered_users))\n",
    "\n",
    "\n",
    "def balance_key(cnts):\n",
    "    m = sum(cnts) / 3.0\n",
    "    var = sum((c - m) ** 2 for c in cnts) / 3.0\n",
    "    std = math.sqrt(var)\n",
    "    total = sum(cnts)\n",
    "    return (std, -total)\n",
    "\n",
    "\n",
    "sorted_users = sorted(filtered_users.items(), key=lambda x: balance_key(x[1]))\n",
    "top_k = 5000\n",
    "top_users = sorted_users[:min(top_k, len(sorted_users))]\n",
    "\n",
    "print(\"Selected top users:\", len(top_users))\n",
    "\n",
    "group_counts = list(zip(*[cnts for _, cnts in top_users]))\n",
    "\n",
    "rows = []\n",
    "for g in range(3):\n",
    "    arr = np.array(group_counts[g], dtype=np.int64)\n",
    "    q1 = float(np.quantile(arr, 0.25))\n",
    "    q3 = float(np.quantile(arr, 0.75))\n",
    "    row = {\n",
    "        \"group\": [\"L\", \"M\", \"H\"][g],\n",
    "        \"min\": int(arr.min()),\n",
    "        \"Q1\": q1,\n",
    "        \"mean\": float(arr.mean()),\n",
    "        \"Q3\": q3,\n",
    "        \"max\": int(arr.max()),\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "df_stats = pd.DataFrame(rows, columns=[\"group\", \"min\", \"Q1\", \"mean\", \"Q3\", \"max\"])\n",
    "print(\"\\n==== Top 5,000 balanced users: Group interaction statistics ====\")\n",
    "print(df_stats.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644f22f",
   "metadata": {},
   "source": [
    "## 2) Item Popularity Stats (items interacted with selected Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80986e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique items interacted by top users: 35405\n",
      "\n",
      "==== Item popularity stats for items interacted by top 5,000 users ====\n",
      "group  min   Q1       mean    Q3   max\n",
      "    L    5  5.0   6.350155   7.0     8\n",
      "    M    9 10.0  12.916723  15.0    18\n",
      "    H   19 41.0 392.749524 328.0 34666\n"
     ]
    }
   ],
   "source": [
    "top_user_ids = {u for u, _ in top_users}\n",
    "\n",
    "user_items = set()\n",
    "with FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        d = json.loads(line)\n",
    "        u = d.get(\"user_id\")\n",
    "        if u not in top_user_ids:\n",
    "            continue\n",
    "        item_id = d.get(\"parent_asin\") or d.get(\"asin\")\n",
    "        if item_id:\n",
    "            user_items.add(item_id)\n",
    "\n",
    "print(\"\\nNumber of unique items interacted by top users:\", len(user_items))\n",
    "\n",
    "vals_L = []\n",
    "vals_M = []\n",
    "vals_H = []\n",
    "\n",
    "for it in user_items:\n",
    "    cnt = item_count.get(it, 0)\n",
    "    g_idx = get_group_idx(cnt)\n",
    "    if g_idx == 0:\n",
    "        vals_L.append(cnt)\n",
    "    elif g_idx == 1:\n",
    "        vals_M.append(cnt)\n",
    "    else:\n",
    "        vals_H.append(cnt)\n",
    "\n",
    "\n",
    "def make_stats(arr):\n",
    "    if not arr:\n",
    "        return {\"min\": None, \"Q1\": None, \"mean\": None, \"Q3\": None, \"max\": None}\n",
    "    arr = np.array(arr, dtype=np.int64)\n",
    "    return {\n",
    "        \"min\": int(arr.min()),\n",
    "        \"Q1\": float(np.quantile(arr, 0.25)),\n",
    "        \"mean\": float(arr.mean()),\n",
    "        \"Q3\": float(np.quantile(arr, 0.75)),\n",
    "        \"max\": int(arr.max()),\n",
    "    }\n",
    "\n",
    "\n",
    "stats_L = make_stats(vals_L)\n",
    "stats_M = make_stats(vals_M)\n",
    "stats_H = make_stats(vals_H)\n",
    "\n",
    "df_item_stats = pd.DataFrame(\n",
    "    [\n",
    "        {\"group\": \"L\", **stats_L},\n",
    "        {\"group\": \"M\", **stats_M},\n",
    "        {\"group\": \"H\", **stats_H},\n",
    "    ],\n",
    "    columns=[\"group\", \"min\", \"Q1\", \"mean\", \"Q3\", \"max\"],\n",
    ")\n",
    "\n",
    "print(\"\\nItem popularity stats for items interacted by top 5,000 users\")\n",
    "print(df_item_stats.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54324e21",
   "metadata": {},
   "source": [
    "## 3) Train/Valid/Test Cold item ratio check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2254201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items in item2id.txt: 29284\n",
      "Global item index range: [0, 29283]\n",
      "\n",
      "Basic stats\n",
      "#train pairs: 33304\n",
      "#valid pairs: 2036\n",
      "#test  pairs: 1949\n",
      "\n",
      "Unique items in train: 23587\n",
      "Unique items in valid: 1618\n",
      "Unique items in test : 1510\n",
      "\n",
      "Overlap between splits (by item index)\n",
      "Items in test ∩ train: 1510\n",
      "Items in test ∩ valid: 425\n",
      "Items in valid ∩ train: 1618\n",
      "Items in all three (train ∩ valid ∩ test): 425\n",
      "\n",
      "Items not appearing in train (cold w.r.t train)\n",
      "Items only in valid (not in train): 0\n",
      "Items only in test  (not in train): 0\n",
      "Items in (valid ∪ test) but not in train: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "DOMAIN = \"Home_and_Kitchen\"\n",
    "DATA_ROOT = f\"/home/heek/aigs/NTS/data/{DOMAIN}\"\n",
    "MAP_DIR = os.path.join(DATA_ROOT, \"maps\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_ROOT, \"train.txt\")\n",
    "VALID_PATH = os.path.join(DATA_ROOT, \"valid.txt\")\n",
    "TEST_PATH  = os.path.join(DATA_ROOT, \"test.txt\")\n",
    "ITEM2ID_PATH = os.path.join(MAP_DIR, \"item2id.txt\")\n",
    "\n",
    "\n",
    "def load_pairs(path):\n",
    "    pairs = []\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            u_str, i_str = line.split()\n",
    "            u = int(u_str)\n",
    "            i = int(i_str)\n",
    "            pairs.append((u, i))\n",
    "            items.append(i)\n",
    "    return pairs, items\n",
    "\n",
    "def load_item2id(path):\n",
    "    idx_set = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            _, idx_str = line.split()\n",
    "            idx = int(idx_str)\n",
    "            idx_set.add(idx)\n",
    "    return idx_set\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_item_indices = load_item2id(ITEM2ID_PATH)\n",
    "    print(f\"Total items in item2id.txt: {len(all_item_indices)}\")\n",
    "    print(f\"Global item index range: [{min(all_item_indices)}, {max(all_item_indices)}]\")\n",
    "    print()\n",
    "\n",
    "    train_pairs, train_items_list = load_pairs(TRAIN_PATH)\n",
    "    valid_pairs, valid_items_list = load_pairs(VALID_PATH)\n",
    "    test_pairs,  test_items_list  = load_pairs(TEST_PATH)\n",
    "\n",
    "    train_items = set(train_items_list)\n",
    "    valid_items = set(valid_items_list)\n",
    "    test_items  = set(test_items_list)\n",
    "\n",
    "    print(\"Basic stats\")\n",
    "    print(f\"#train pairs: {len(train_pairs)}\")\n",
    "    print(f\"#valid pairs: {len(valid_pairs)}\")\n",
    "    print(f\"#test  pairs: {len(test_pairs)}\")\n",
    "    print()\n",
    "    print(f\"Unique items in train: {len(train_items)}\")\n",
    "    print(f\"Unique items in valid: {len(valid_items)}\")\n",
    "    print(f\"Unique items in test : {len(test_items)}\")\n",
    "    print()\n",
    "\n",
    "    # overlap check\n",
    "    print(\"Overlap between splits (by item index)\")\n",
    "    print(f\"Items in test ∩ train: {len(test_items & train_items)}\")\n",
    "    print(f\"Items in test ∩ valid: {len(test_items & valid_items)}\")\n",
    "    print(f\"Items in valid ∩ train: {len(valid_items & train_items)}\")\n",
    "    print(f\"Items in all three (train ∩ valid ∩ test): {len(train_items & valid_items & test_items)}\")\n",
    "    print()\n",
    "\n",
    "    valid_only_items = valid_items - train_items\n",
    "    test_only_items  = test_items - train_items\n",
    "    valid_test_only_items = (valid_items | test_items) - train_items\n",
    "\n",
    "    print(\"Items not appearing in train (cold w.r.t train)\")\n",
    "    print(f\"Items only in valid (not in train): {len(valid_only_items)}\")\n",
    "    print(f\"Items only in test  (not in train): {len(test_only_items)}\")\n",
    "    print(f\"Items in (valid ∪ test) but not in train: {len(valid_test_only_items)}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54b860",
   "metadata": {},
   "source": [
    "# 3. Item meta data embedding related"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cb1a8",
   "metadata": {},
   "source": [
    "## 1) where to fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e4bdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "item_id      : B009EA1AH4\n",
      "main_category: Amazon Home\n",
      "categories   : ['Home & Kitchen', 'Bath', 'Bathroom Accessories', 'Shower Curtains, Hooks & Liners', 'Shower Curtains']\n",
      "title        : LORRAINE HOME FASHIONS Blaze Shower Curtain, 70 by 72-Inch, Platinum\n",
      "description  : ['Jacquard woven fabric shower curtain in flame stich motif with lurex thread accent. great design for the bathroom.']\n",
      "================================================================================\n",
      "item_id      : B0BLRSD96N\n",
      "main_category: Appliances\n",
      "categories   : ['Home & Kitchen', 'Vacuums & Floor Care', 'Vacuum Parts & Accessories', 'Filters', 'Upright Filters']\n",
      "title        : Bogda Filter Replacement (6 Pack) Compatible with Shark ION Robot RV700_N RV720_N RV851WV RV850 and Shark IQ Robot R101AE RV1001AE UR1005AE Vacuum Cleaner Replace Part #RVFFK950\n",
      "description  : []\n",
      "================================================================================\n",
      "item_id      : B01MY8FHE9\n",
      "main_category: Amazon Home\n",
      "categories   : ['Home & Kitchen', 'Bedding', \"Kids' Bedding\", 'Bedding Sets & Collections', 'Bedspread & Coverlet Sets']\n",
      "title        : Urban Habitat Kids Trixie Twin/Twin XL Bedding for Girls Quilt Set - Purple, Geometric – 4 Piece Kids Girls Quilts – Cotton Quilt Sets Coverlet\n",
      "description  : ['Update your room with the chic style of the Urban Habitat Kids Trixie 4 Piece Coverlet Set. The coverlet is made from 100% cotton and features fun geometric patterns in purple, grey, black, and white. Extra dimension and charm is added to the motif with various geometric designs on each hexagon. This coverlet has a solid purple reverse. One pillow features a pleated look and the other is embroidered with coordinating polka dots. Pre-washed and pre-shrunk, this coverlet set is hypoallergenic and bed-ready right out of the package.']\n",
      "================================================================================\n",
      "item_id      : B0017L6CB2\n",
      "main_category: Amazon Home\n",
      "categories   : ['Home & Kitchen', 'Storage & Organization', 'Clothing & Closet Storage', 'Shoe Organizers', 'Free Standing Shoe Racks']\n",
      "title        : Whitmor 2 Tier Stackable Closet Shelves - Chrome\n",
      "description  : ['Product Description', \"Whitmor's 2 Tier Stackable Closet Shelves is perfect for entryway and closet shoe storage. These modular shelves cna be stacked with other units to increase storage space. These shelves fit perfectly in closets under hanging clothes. Constructed with durable, all-metal chrome. With easy, no tools assembly, these 2 tier stackable shelves can store shoes, folded garments, and accessories to free up other floor space. Whitmor is a 4th generation family-owned and operated business. Since 1946, Whitmor has been dedicated to bringing organization home by creating products that simplify everyday life. Ensuring that those products are built with integrity, value, and innovation is our commitment to you. And our promise is that we will always be here for you should you ever need us as we stand behind our product 100%. Whitmor customer service is available in English and Spanish Monday through Friday from 8am - 4:30pm CST. Call us and we will gladly assist you in your language.\", 'Brand Story', 'By', 'From the Manufacturer', 'Closet shelves that can be stacked for more storage. Beautiful chromed fixture is great for sweaters, accessories, shoes, purses etc. Unit measures 12-Inch by 30-Inch by 16.63-Inch.', 'See more']\n",
      "================================================================================\n",
      "item_id      : B074X3JKKK\n",
      "main_category: Amazon Home\n",
      "categories   : ['Home & Kitchen', 'Kitchen & Dining', 'Small Appliances', 'Blenders', 'Countertop Blenders']\n",
      "title        : 1500W Professional Smoothie and Shake Blender with 6 Programmed Settings, Pulse Feature, 67 Oz / 8 Cup BPA-Free Pitcher\n",
      "description  : []\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# load metadata json\n",
    "META_PATH = Path(\"/home/heek/edda_backbone/preprocess_raw/amazon/23/filtered_data/f_item_meta/f_meta_Home_and_Kitchen.json\")\n",
    "\n",
    "# read json file\n",
    "with META_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# meta is a list → convert to dict indexed by item_id\n",
    "item_dict = {}\n",
    "for entry in meta:\n",
    "    if not isinstance(entry, dict):\n",
    "        continue\n",
    "\n",
    "    item_id = entry.get(\"parent_asin\") or entry.get(\"asin\")\n",
    "    if item_id:\n",
    "        item_dict[item_id] = entry\n",
    "\n",
    "# sample 5 random items\n",
    "sample_items = random.sample(list(item_dict.keys()), 5)\n",
    "\n",
    "# print fields\n",
    "for item in sample_items:\n",
    "    info = item_dict[item]\n",
    "\n",
    "    main_cat = info.get(\"main_category\")\n",
    "    cats = info.get(\"categories\")\n",
    "    title = info.get(\"title\")\n",
    "    desc = info.get(\"description\")\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"item_id      : {item}\")\n",
    "    print(f\"main_category: {main_cat}\")\n",
    "    print(f\"categories   : {cats}\")\n",
    "    print(f\"title        : {title}\")\n",
    "    print(f\"description  : {desc}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31c659",
   "metadata": {},
   "source": [
    "## 2) Embedding Result Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582c185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#items = 29284, dim = 64\n",
      "fields = ['main_category', 'categories', 'title', 'description']\n",
      "\n",
      "============================================================\n",
      "item_idx = 7723, item_id = B00GY8ZIRM\n",
      "  [main_category] emb[:8] = [-0.0203, 0.1814, -0.3674, 0.0737, 0.2086, 0.0422, -0.0488, -0.0788]  ...\n",
      "  [categories] emb[:8] = [-0.1256, 0.0142, -0.3931, 0.0204, 0.1085, -0.0790, -0.0891, -0.1803]  ...\n",
      "  [title] emb[:8] = [-0.0897, 0.1412, -0.3264, -0.0217, 0.0063, -0.0372, -0.0409, -0.1941]  ...\n",
      "  [description] emb[:8] = [0.0345, 0.1020, -0.3936, -0.0524, 0.0989, -0.0729, -0.0055, -0.0258]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 24614, item_id = B09KRC6P9Z\n",
      "  [main_category] emb[:8] = [-0.0203, 0.1814, -0.3674, 0.0737, 0.2086, 0.0422, -0.0488, -0.0788]  ...\n",
      "  [categories] emb[:8] = [-0.0665, 0.1022, -0.3586, -0.0197, 0.1052, -0.1370, -0.1925, -0.0668]  ...\n",
      "  [title] emb[:8] = [-0.0647, 0.0577, -0.4199, -0.0764, 0.0075, -0.1266, -0.1279, 0.0130]  ...\n",
      "  [description] emb[:8] = [-0.0284, 0.0823, -0.3962, -0.0458, 0.0589, -0.1307, -0.0472, 0.0757]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 23971, item_id = B098QQ3H4M\n",
      "  [main_category] emb[:8] = [-0.0203, 0.1814, -0.3674, 0.0737, 0.2086, 0.0422, -0.0488, -0.0788]  ...\n",
      "  [categories] emb[:8] = [0.0055, 0.2225, -0.4910, 0.0595, 0.0674, -0.0251, -0.1045, -0.0200]  ...\n",
      "  [title] emb[:8] = [-0.0826, 0.1753, -0.5884, -0.1337, 0.0175, 0.0178, 0.0357, 0.0041]  ...\n",
      "  [description] emb[:8] = [-0.0131, 0.2822, -0.6230, -0.1032, -0.0227, 0.0397, 0.0282, 0.0921]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 10589, item_id = B0127DGCUY\n",
      "  [main_category] emb[:8] = [-0.0203, 0.1814, -0.3674, 0.0737, 0.2086, 0.0422, -0.0488, -0.0788]  ...\n",
      "  [categories] emb[:8] = [-0.0210, 0.1957, -0.3870, 0.0317, 0.1541, -0.0050, -0.1116, -0.0930]  ...\n",
      "  [title] emb[:8] = [0.0816, 0.1098, -0.4302, -0.0684, 0.1492, -0.0626, -0.0081, -0.0751]  ...\n",
      "  [description] emb[:8] = [0.0667, 0.1627, -0.5151, -0.0053, 0.0890, -0.1181, -0.0675, 0.0349]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 18390, item_id = B07N5YHLNH\n",
      "  [main_category] emb[:8] = [-0.0203, 0.1814, -0.3674, 0.0737, 0.2086, 0.0422, -0.0488, -0.0788]  ...\n",
      "  [categories] emb[:8] = [-0.1558, 0.2495, -0.4182, 0.0182, 0.0510, 0.0101, -0.0986, -0.2321]  ...\n",
      "  [title] emb[:8] = [-0.1327, 0.2461, -0.4565, -0.1466, 0.0354, -0.0358, -0.0302, -0.1483]  ...\n",
      "  [description] emb[:8] = [-0.1351, 0.3152, -0.5410, -0.0751, -0.0234, -0.0496, -0.0553, -0.0660]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 10864, item_id = B014Q7KYPS\n",
      "  [main_category] emb[:8] = [-0.0203, 0.1814, -0.3674, 0.0737, 0.2086, 0.0422, -0.0488, -0.0788]  ...\n",
      "  [categories] emb[:8] = [0.0384, 0.1694, -0.3154, -0.0372, 0.0077, -0.0667, -0.0546, -0.0851]  ...\n",
      "  [title] emb[:8] = [0.0230, 0.1957, -0.3740, -0.0992, 0.0224, 0.0800, 0.1067, -0.0078]  ...\n",
      "  [description] emb[:8] = [0.0252, 0.2095, -0.3652, -0.0827, 0.0237, 0.0725, 0.1142, -0.0216]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 28791, item_id = B0C53DY25B\n",
      "  [main_category] emb[:8] = [-0.1118, 0.0840, -0.3586, 0.0485, 0.0870, 0.0557, -0.0216, -0.1494]  ...\n",
      "  [categories] emb[:8] = [0.0079, 0.2155, -0.4077, -0.0516, -0.0396, -0.0325, -0.1710, -0.1777]  ...\n",
      "  [title] emb[:8] = [-0.1367, 0.1648, -0.5356, -0.0821, -0.0594, -0.0133, -0.2097, -0.0349]  ...\n",
      "  [description] emb[:8] = [0.1243, 0.2091, -0.5293, -0.1166, -0.0408, -0.0142, -0.0481, -0.0517]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 8311, item_id = B00K8HQ62G\n",
      "  [main_category] emb[:8] = [-0.0203, 0.1814, -0.3674, 0.0737, 0.2086, 0.0422, -0.0488, -0.0788]  ...\n",
      "  [categories] emb[:8] = [-0.1043, 0.1028, -0.4370, -0.0023, 0.0579, -0.0526, -0.1251, -0.1105]  ...\n",
      "  [title] emb[:8] = [0.0049, -0.0034, -0.5083, 0.1206, 0.1061, 0.0955, -0.0837, -0.0801]  ...\n",
      "  [description] emb[:8] = [-0.0702, 0.0710, -0.3894, 0.1010, 0.0684, 0.0604, -0.0478, 0.0478]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 5276, item_id = B007DCM5TW\n",
      "  [main_category] emb[:8] = [-0.0032, -0.0613, -0.3960, -0.0668, 0.0363, 0.1061, -0.1146, -0.1624]  ...\n",
      "  [categories] emb[:8] = [-0.1268, 0.1078, -0.3728, -0.0014, 0.0436, -0.0071, -0.1732, 0.0388]  ...\n",
      "  [title] emb[:8] = [-0.0845, 0.1158, -0.4443, -0.0637, -0.0749, -0.0294, -0.1851, 0.0887]  ...\n",
      "  [description] emb[:8] = [0.0518, 0.0999, -0.4504, -0.1062, -0.0352, -0.0451, -0.0624, -0.0473]  ...\n",
      "\n",
      "============================================================\n",
      "item_idx = 1630, item_id = B000WNJH1S\n",
      "  [main_category] emb[:8] = [-0.0033, -0.0614, -0.3958, -0.0668, 0.0362, 0.1061, -0.1144, -0.1624]  ...\n",
      "  [categories] emb[:8] = [0.0575, 0.1274, -0.3770, 0.0490, -0.0124, -0.0718, -0.2032, -0.1260]  ...\n",
      "  [title] emb[:8] = [0.0365, 0.0914, -0.4504, -0.0931, -0.0996, 0.0512, -0.1008, -0.1236]  ...\n",
      "  [description] emb[:8] = [0.0883, 0.0894, -0.4888, 0.0188, 0.0185, 0.0636, -0.0527, 0.0536]  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PKL_PATH = \"/home/heek/aigs/NTS/data/Home_and_Kitchen/itm_txt_emb/itm_txt_emb_home.pkl\"\n",
    "\n",
    "def main():\n",
    "    with open(PKL_PATH, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    field_embs = data[\"field_emb\"]   \n",
    "    idx2item = data[\"idx2item\"]     \n",
    "    meta = data[\"meta\"]\n",
    "\n",
    "    fields = meta[\"fields\"]         # [\"main_category\", \"categories\", \"title\", \"description\"]\n",
    "    n_items = len(idx2item)\n",
    "    dim = meta[\"dim\"]\n",
    "\n",
    "    print(f\"#items = {n_items}, dim = {dim}\")\n",
    "    print(f\"fields = {fields}\")\n",
    "    print()\n",
    "\n",
    "    np.random.seed(0)\n",
    "    sample_indices = np.random.choice(n_items, size=10, replace=False)\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        item_id = idx2item[idx]\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"item_idx = {idx}, item_id = {item_id}\")\n",
    "        for field in fields:\n",
    "            emb = field_embs[field][idx]   # (dim,)\n",
    "            head_str = \", \".join([f\"{v:.4f}\" for v in emb[:8]])\n",
    "            print(f\"  [{field}] emb[:8] = [{head_str}]  ...\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heater",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
